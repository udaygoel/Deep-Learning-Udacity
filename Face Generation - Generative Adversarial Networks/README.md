# Face Generation - Generative Adversarial Networks
This project creates a Generative Adversarial Network (GAN) to generate new images of human faces. The GAN consists of a Generator and a Discriminator. The Generator creates new images using an input vector and the Discriminator compares the generated new image with the actual image. The network trains as the Generator learns to create new images (with no knowledge of actual image) that the Discriminator will accept as the true image, while the Discriminator learns to identify the new image as different from the actual image.  

### Project Files

The project uses these files and folders:

- [dlnd_face_generation.ipynb](https://github.com/udaygoel/Deep-Learning-Udacity/blob/master/Face%20Generation%20-%20Generative%20Adversarial%20Networks/dlnd_face_generation.ipynb): This Jupyter Notebook covers the project. It starts with the analysis and processing of the data and then progressively builds the GAN model. 
- helper.py: helper functions to process, load and display the data. This is provided by Udacity.
- problem_unittests.py: Unit tests to test the functions created in the notebook. This is provided by Udacity.

The project does not include these files due to space constraints:

- data/mnist: This folder contains 59,996 images from MNIST database
- data/img_align_celeba: This folder contains 202,599 images from the [CelebFaces Attributes Dataset (CelebA)](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) database

### Contents

There are 5 main sections of the Project.

1. Explore the Data. 

   We explore that data for MNIST and CelebA using the helper functions. The CelebA images are cropped to 28x28 shape.

2. Building the Neural Network

   The Neural Network is created using TensorFlow. The following are modelled in the Network:

   - Model_inputs: These are tensorflow placeholders for the inputs in the training process
   - Discriminator: This is the discrimator neural network that discriminates on images created by the generator. 
   - Generator: This is the generator neural network that generates an image using input vector z.
   - Model Loss: This provides the loss for both Generator and Discriminator
   - Optimization: This optimizes the Generator and Discriminator

3. Training the Neural Network

   We define the training function for the network such that it can be used to train on both the MNIST and CelebA data. Only the model architecture and the training functions are same across the 2 datasets and the actual trained network weights will be different.

4. Training on MNIST Data

   The network is trained on MNIST Data on 2 epochs. The output generated by the Generator is displayed after after 100 steps. As the model is trained, the output starts to resemble hand written digits, similar to the MNIST data.

5. Training on CelebA Data

   The network is trained on CelebA Data on 1 epoch. The output generated by the Generator is displayed after after 100 steps. As the model is trained, the output starts to resemble human faces, similar to the CelebA data that we saw in Step 1.


The images generated for CelebA data can be clearly seen as human faces. Due to the compute time required to train the network, the number of epoch was kept at 1. Further improvement can be made by increasing the number of epochs and optimization of the network hyperparameters.